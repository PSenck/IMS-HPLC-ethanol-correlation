{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#imports\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "import plotly.graph_objects as go\r\n",
    "from plotly.subplots import make_subplots\r\n",
    "\r\n",
    "import os.path\r\n",
    "import glob\r\n",
    "\r\n",
    "from IMS_functions import load_raw_data, alignment, integrate_spectrum, baseline_correction\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler            \r\n",
    "from sklearn.decomposition import PCA\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fermentation = {\"ferm3\" : \"Fermentation 3\", \"ferm6\" : \"Fermentation 6\", \"ferm7\" : \"Fermentation 7\"}\r\n",
    "\r\n",
    "#load metadata and create dict with start and endpoints\r\n",
    "metadata = pd.read_excel(r\"C:\\IMS\\metadata_IMS.xlsx\", index_col = \"fermentation\")\r\n",
    "\r\n",
    "exp_numbers =[3,6,7]  \r\n",
    "\r\n",
    "start_dict = {}\r\n",
    "for  timestamp, i  in zip([metadata[\"start_IMS\"].loc[nr] for nr in exp_numbers], exp_numbers):\r\n",
    "    start_dict[\"ferm{0}\".format(i)]= timestamp\r\n",
    "\r\n",
    "end_dict = {}\r\n",
    "for  timestamp, i  in zip([metadata[\"end_IMS\"].loc[nr] for nr in exp_numbers], exp_numbers):  \r\n",
    "    end_dict[\"ferm{0}\".format(i)]= timestamp\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#load offline measured HPLC ethanol data and save it in dict with key: ferm.Nr. value: DataFrame\r\n",
    "path_Off = r'C:\\IMS\\Offline'             \r\n",
    "offline_files = [os.path.join(path_Off,\"offline{0}.xlsx\".format(i)) for i in exp_numbers]         \r\n",
    "offline_dict = {}\r\n",
    "\r\n",
    "for f, i in zip(offline_files, exp_numbers):                        \r\n",
    "    offline_dict[\"ferm{0}\".format(i)] = pd.read_excel(f, usecols = [0,4], names =[\"ts\",\"cE\"] )   \r\n",
    "\r\n",
    "#filter according to desired time\r\n",
    "for ferm, df in offline_dict.items():\r\n",
    "    df = df[(df[\"ts\"] >= start_dict[ferm] ) &  (df[\"ts\"] <= end_dict[ferm])]\r\n",
    "    df.set_index(\"ts\", inplace = True)\r\n",
    "    offline_dict[ferm] = df\r\n",
    "    \r\n",
    "offline_merged_df = pd.concat([val for val in offline_dict.values()])\r\n",
    "\r\n",
    "\r\n",
    "#create a list of list with file paths for each measurement at different days\r\n",
    "path3 = r\"C:\\IMS\\IMS_3\"\r\n",
    "path6 = r\"C:\\IMS\\IMS_6\"\r\n",
    "path7 = r\"C:\\IMS\\IMS_7\"\r\n",
    "path_list = [path3, path6, path7]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#load measured IMS data and save each spectrum in a dictionary with key: timestamp, value: DataFrame (2D spectrum)\r\n",
    "dat_wide_as_dict = load_raw_data(path_list = path_list ,S_ds = 1, N_ds = 1, start_dict = start_dict,  end_dict = end_dict)  \r\n",
    "\r\n",
    "#Align spectra. Create common drift_time grid, set RIP peak to 1 and relate other peaks to it. \r\n",
    "dat_wide_as_dict = alignment(dat_wide_as_dict)\r\n",
    "\r\n",
    "#Note, if a large ammount of datasets is processed with alignment(), an error can occur. Solution: reduce the ammount of data by downsampling with N_ds or use another end timepoint to read less data."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # generate static images to show 2D plot\r\n",
    "# #If you execute this cell, the rest of the code works very slowly, better do it at the end\r\n",
    "# zmax = 1000 # max. value for color scale\r\n",
    "\r\n",
    "# few_ts = [list(dat_wide_as_dict.keys())[i] for i in np.arange(0, len(dat_wide_as_dict), 60)]\r\n",
    "\r\n",
    "# for ts in few_ts:\r\n",
    "#     fig = px.imshow(dat_wide_as_dict[ts], labels={'y': 'Retention time [s]', 'x': 'Normalized drift time', 'z' : 'Signal intensity [a.u.]'},               #zaxis?\r\n",
    "#                     aspect='auto', title=str(ts), origin='lower', zmin=0, zmax = zmax)\r\n",
    "#     fig.show()\r\n",
    "#     break\r\n",
    "#     if ts >= pd.to_datetime(\"2020-12-03 12:00\") & ts <= pd.to_datetime(\"2020-12-03 12:30\"):\r\n",
    "#         break\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#integrate at each drift_time over all retention times and save results in a data frame, whereas each row is an integrated 1D spectrum.\r\n",
    "col_sum_df = integrate_spectrum(dat_wide_as_dict)\r\n",
    "\r\n",
    "# discard first and last 10% of the spectrum possibly containing interference signals, beneficial for subsequent Baseline correction.\r\n",
    "min_max = {\"min\" : 0.1, \"max\" : 0.9}\r\n",
    "filter = (col_sum_df.columns >= min_max[\"min\"]*np.max(col_sum_df.columns)) & (col_sum_df.columns <= min_max[\"max\"]*np.max(col_sum_df.columns))\r\n",
    "col_sum_df =  col_sum_df.loc[:, [col for col in filter]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot without baseline correction \r\n",
    "for t,row in col_sum_df.iterrows():\r\n",
    "    fig = px.line(y = row, x = col_sum_df.columns)\r\n",
    "    fig.update_xaxes(title_text=\"Normalized drift time\") \r\n",
    "    fig.update_yaxes(title_text=\"Signal intensity [a.u.]\") \r\n",
    "    fig.show()\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#baseline correction\r\n",
    "col_sum_df = baseline_correction(col_sum_df, \"Zhang\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot with baseline correction \r\n",
    "for t,row in col_sum_df.iterrows():\r\n",
    "    fig = px.line(y = row, x = col_sum_df.columns)\r\n",
    "    fig.update_xaxes(title_text=\"Normalized drift time\") \r\n",
    "    fig.update_yaxes(title_text=\"Signal intensity [a.u.]\") \r\n",
    "    fig.show()\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PCA_drift_borders = {\"start\" : 1.02, \"end\" : 1.18}      #drift_time span considered for PCA,  including the two ethanol peaks\r\n",
    "\r\n",
    "filter = (col_sum_df.columns.values >= PCA_drift_borders[\"start\"] ) &  (col_sum_df.columns.values <= PCA_drift_borders[\"end\"])\r\n",
    "col_sum_df_filtered = col_sum_df.iloc[:, [col for col in filter]]\r\n",
    "\r\n",
    "#perform PCA and save PC1 and PC2 values in dataframe \r\n",
    "x = col_sum_df_filtered.values\r\n",
    "x = StandardScaler().fit_transform(x) \r\n",
    "\r\n",
    "\r\n",
    "pca = PCA(n_components=2)\r\n",
    "principalComponents = pca.fit_transform(x)      \r\n",
    "\r\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'], index = col_sum_df.index)\r\n",
    "\r\n",
    "fig = px.scatter(principalDf, x=\"principal component 1\", y=\"principal component 2\", color= principalDf.index)    \r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot drift-time section used in PCA\r\n",
    "for t,row in col_sum_df_filtered.iterrows():\r\n",
    "    fig = px.line(y = row, x = col_sum_df_filtered.columns)\r\n",
    "    fig.update_xaxes(title_text=\"Normalized drift time\") \r\n",
    "    fig.update_yaxes(title_text=\"Signal intensity [a.u.]\") \r\n",
    "    fig.show()\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#find the closest IMS to HPLC measurements\r\n",
    "PCA_dict = {}\r\n",
    "for ferm , df in offline_dict.items():\r\n",
    "    correlation_indices = [principalDf.index.get_loc(r, 'nearest') for r in df.index.values]\r\n",
    "    new = principalDf.iloc[correlation_indices]       \r\n",
    "    new[\"cE\"] = df[\"cE\"].values\r\n",
    "    new[\"Fermentation\"] = fermentation[ferm]  #vorher ferm\r\n",
    "    PCA_dict[ferm] = new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot ethanol concentration vs PC1 and PC2 for each experiment\r\n",
    "for ferm, df in PCA_dict.items():\r\n",
    "    fig = make_subplots(cols = 2)\r\n",
    "\r\n",
    "    df = df[df[\"cE\"] > 0.0] #everything above cE == 0.0\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x= df[\"principal component 1\"] , y= df[\"cE\"], name= \"HPLC vs. PC1  \" ,  mode = \"markers\", marker = dict(color =  \"green\", size = 5), text = df.index), row= 1 , col = 1)\r\n",
    "    fig.add_trace(go.Scatter(x= df[\"principal component 2\"], y= df[\"cE\"], name= \"HPLC vs. PC2  \", mode = \"markers\", marker = dict(color =  \"red\" , size = 5),text = df.index), row= 1 , col = 2)\r\n",
    "    fig.update_yaxes(title_text=\"Ethanol HPLC [g/L]\")\r\n",
    "    [fig.update_xaxes(title_text= PC, row=1, col= col) for PC, col in zip([\"Principal component 1\", \"Principal component 2\"], [1,2])]\r\n",
    "    fig.update_layout(title_text = fermentation[ferm])\r\n",
    "    fig.update_layout(width=1200)\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot ethanol concentration vs PC1 for all experiments\r\n",
    "PCA_df = pd.concat([val for val in PCA_dict.values()])\r\n",
    "PCA_df = PCA_df[PCA_df[\"cE\"] > 0] #everything above cE == 0.0\r\n",
    "fig = px.scatter(PCA_df, x= \"principal component 1\" , y= \"cE\", color= \"Fermentation\", hover_name= PCA_df.index , labels = {\"Fermentation\" : \"Experiment\"})  #, labels = {\"Fermentation\" : \"Experiment\"}\r\n",
    "fig.update_yaxes(title_text=\"Ethanol HPLC [g/L]\")\r\n",
    "fig.update_xaxes(title_text=\"Principal component 1\")     \r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot ethanol concentration vs PC2 for all experiments\r\n",
    "PCA_df = pd.concat([val for val in PCA_dict.values()])\r\n",
    "PCA_df = PCA_df[PCA_df[\"cE\"] > 0] #everything above cE == 0.0\r\n",
    "fig = px.scatter(PCA_df, x= \"principal component 2\" , y= \"cE\", color= \"Fermentation\", hover_name= PCA_df.index , labels = {\"Fermentation\" : \"Experiment\"})  #, labels = {\"Fermentation\" : \"Experiment\"}\r\n",
    "fig.update_yaxes(title_text=\"Ethanol HPLC [g/L]\")\r\n",
    "fig.update_xaxes(title_text=\"Principal component 2\")     \r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#statistics to demonstrate how PC1 correlate with measured HPLC ethanol concentration\r\n",
    "# Pearson coefficient  \r\n",
    "pearson_coeff = PCA_df[\"principal component 1\"].corr(PCA_df[\"cE\"], method = \"pearson\")\r\n",
    "\r\n",
    "#Spearman coefficient  \r\n",
    "spearman_coeff = PCA_df[\"principal component 1\"].corr(PCA_df[\"cE\"], method = \"spearman\")\r\n",
    "\r\n",
    "print(pearson_coeff, spearman_coeff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#perform linear regression model for predicting ethanol concentrations \r\n",
    "from sklearn.linear_model import LinearRegression \r\n",
    "from copy import deepcopy\r\n",
    "\r\n",
    "#Training data without ferm3\r\n",
    "#no_ferm3_PCA = PCA_df[(PCA_df.index >= pd.to_datetime(\"2020-12-03 08:00\"))]\r\n",
    "\r\n",
    "#comment in or out or in, whether use training data with or without ferm 3\r\n",
    "# X = no_ferm3_PCA.loc[: ,[\"principal component 1\"]].values.reshape(-1,1)\r\n",
    "# Y = no_ferm3_PCA.loc[: ,[\"cE\"]].values.reshape(-1,1)\r\n",
    "#\r\n",
    "#comment in or out \" \r\n",
    "X = PCA_df.loc[: ,[\"principal component 1\"]].values.reshape(-1,1)\r\n",
    "Y = PCA_df.loc[: ,[\"cE\"]].values.reshape(-1,1)\r\n",
    "#\r\n",
    "\r\n",
    "lr = LinearRegression()\r\n",
    "lr.fit(X,Y)\r\n",
    "\r\n",
    "#predict\r\n",
    "X = principalDf.loc[: ,[\"principal component 1\"]].values.reshape(-1,1)\r\n",
    "Y_pred = lr.predict(X)\r\n",
    "prediction_df = deepcopy(principalDf)\r\n",
    "prediction_df[\"ethanol_IMS\"] = Y_pred\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "filter1 = (prediction_df.index >= pd.to_datetime(\"2020-11-18 13:37\")) & (prediction_df.index <= pd.to_datetime(\"2020-11-19 13:00\"))\r\n",
    "filter2 = (prediction_df.index >= pd.to_datetime(\"2020-12-03 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-04 13:00\"))\r\n",
    "filter3 = (prediction_df.index >= pd.to_datetime(\"2020-12-09 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-10 13:00\"))\r\n",
    "\r\n",
    "IMS_dict = {\"ferm3\" : prediction_df[filter1], \"ferm6\" : prediction_df[filter2], \"ferm7\" : prediction_df[filter3]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot measured ethanol concentration (HPLC) and predicted ethanol concentration (IMS -> PCA/Linear regression)\r\n",
    "line_markers = \"lines+markers\"\r\n",
    "for [ferm, df1], df2 in zip(IMS_dict.items(), offline_dict.values()):\r\n",
    "\r\n",
    "    fig = make_subplots()\r\n",
    "    fig.add_trace(go.Scatter(x= df1.index, y= df1[\"ethanol_IMS\"][df1[\"ethanol_IMS\"] >= 0], name = \"Ethanol estimated\", mode = \"lines+markers\"))   # stop at ethanol 0 [g/L]\r\n",
    "    fig.add_trace(go.Scatter(x= df2.index, y= df2[\"cE\"], name = \"Ethanol HPLC\", mode = \"lines+markers\"))\r\n",
    "    fig.update_xaxes(title_text=\"Day/Time\")\r\n",
    "    fig.update_yaxes(title_text=\"Ethanol [g/L]\")\r\n",
    "    fig.update_layout(title_text = fermentation[ferm])\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#conventional feature extraction attempt: finding respective peaks, integrate peak area and correlate it with HPLC measured ethanol concentration. \r\n",
    "from scipy.signal import find_peaks, peak_prominences, peak_widths\r\n",
    "from IMS_functions import get_value, integrate_peaks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#with scipys algorythm \"find_peaks\" it is possible to locate the peak maxima\r\n",
    "#just to show outcome the algorythm not necessarily needed in this workflow\r\n",
    "peak_list = []\r\n",
    "for t, row in col_sum_df.iterrows():      \r\n",
    "    peaks = find_peaks(row,  height = 30e3, threshold = 10, distance = 1)\r\n",
    "    height = peaks[1]['peak_heights']\r\n",
    "    peak_pos = col_sum_df.columns.values[peaks[0]]\r\n",
    "    peak_list.append([height, peak_pos])\r\n",
    "\r\n",
    "peak_df = pd.DataFrame(peak_list, columns = [\"height\", \"peak_pos\"], index = col_sum_df.index)\r\n",
    "\r\n",
    "line_markers = \"lines+markers\"\r\n",
    "line = \"lines\"\r\n",
    "\r\n",
    "for i in np.arange(0, len(col_sum_df), 20):     #display only few peaks\r\n",
    "    print(i)\r\n",
    "    fig = make_subplots()       \r\n",
    "    fig.add_trace(go.Scatter(x= col_sum_df.columns, y= col_sum_df.iloc[i], name= str(\"Signal\"), mode = line))\r\n",
    "    fig.add_trace(go.Scatter(x= peak_df[\"peak_pos\"].iloc[i], y= peak_df[\"height\"].iloc[i], name= \"Peak position\", mode = \"markers\", marker = dict(color =  \"red\", size = 4)))\r\n",
    "    fig.layout[\"yaxis\"].title.text = \"Signal intensity [a.u.]\"\r\n",
    "    fig.layout[\"xaxis\"].title.text = \"Normalized drift time\"\r\n",
    "    fig.update_layout(title_text = str(col_sum_df.index[i]))\r\n",
    "\r\n",
    "    #fig.update_layout(showlegend=False)\r\n",
    "    fig.show() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# filter according to desired range\r\n",
    "drift_borders =  {\"start\" : 0.9, \"end\" : 1.3}                   \r\n",
    "filter = (col_sum_df.columns >= drift_borders[\"start\"] ) &  (col_sum_df.columns <= drift_borders[\"end\"])\r\n",
    "col_sum_df_filtered = col_sum_df.iloc[:, [col for col in filter]]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#again create peaks for filtered region\r\n",
    "\r\n",
    "#create dataframe with peak_position, peak_heights, peak_widths and left/right indices \r\n",
    "\r\n",
    "#peaks\r\n",
    "peak_list = []\r\n",
    "for t, row in col_sum_df_filtered.iterrows():\r\n",
    "    peaks = find_peaks(row,  height = 15e3, threshold = 1, distance = 1)     #height and distance may need to be optimized\r\n",
    "    height = peaks[1]['peak_heights']\r\n",
    "    peak_index = peaks[0]\r\n",
    "    peak_pos = col_sum_df_filtered.columns.values[peaks[0]]\r\n",
    "    peak_list.append([peak_pos, height, peak_index, t])\r\n",
    "\r\n",
    "peak_df = pd.DataFrame(peak_list, columns = [\"position\", \"height\", \"pos_index\", \"t\"]).set_index(\"t\")\r\n",
    "\r\n",
    "#peak start and end\r\n",
    "width_list = []\r\n",
    "for t, row in col_sum_df_filtered.iterrows():\r\n",
    "\r\n",
    "    widths, h_eval, left_ips_index, right_ips_index = peak_widths(row.values, peak_df[\"pos_index\"].loc[t], rel_height=0.8) #left/right indices at 80% rel peak height\r\n",
    "    left_ips =  np.array(col_sum_df_filtered.columns[[np.int(left_ips_index[i]) for i in range(len(left_ips_index))]])\r\n",
    "    right_ips =  np.array(col_sum_df_filtered.columns[[np.int(right_ips_index[i]) for i in range(len(right_ips_index))]])\r\n",
    "    width_list.append([widths, h_eval, left_ips,  left_ips_index, right_ips, right_ips_index])\r\n",
    "\r\n",
    "\r\n",
    "width_df = pd.DataFrame(width_list, columns = [\"widths\", \"h_eval\", \"left_ips\", \"left_ips_index\", \"right_ips\", \"right_ips_index\"], index = peak_df.index.values)\r\n",
    "peak_df = pd.concat([peak_df, width_df], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#search for the left_ips and right_ips values between borders of the ethanol 1 and ethanol 2 peak\r\n",
    "\r\n",
    "#this numbers were taken from a spectrum and may not be sufficiently accurate to describe values at another rel_height than 0.8 \r\n",
    "Et_1 = {\"start\" : 1.026, \"end\" : 1.075, \"left\" : 1.034804, \"right\" : 1.051937}      #borders (start, end) to search within the nearest values (left/right taken) taken from plots by roughly eye determination\r\n",
    "Et_2 = {\"start\" : 1.10, \"end\" : 1.165, \"left\" : 1.120467, \"right\" : 1.146}            #same for ethanol 2 peak\r\n",
    "\r\n",
    "\r\n",
    "ethanol_list =[]\r\n",
    "for t, row in peak_df[[\"left_ips\", \"right_ips\"]].iterrows():\r\n",
    "        \r\n",
    "    Et1_left = get_value(row[\"left_ips\"], Et_1[\"start\"], Et_1[\"end\"], Et_1[\"left\"])\r\n",
    "    Et1_right = get_value(row[\"right_ips\"], Et_1[\"start\"], Et_1[\"end\"], Et_1[\"right\"])\r\n",
    "    Et2_left = get_value(row[\"left_ips\"], Et_2[\"start\"], Et_2[\"end\"], Et_2[\"left\"])\r\n",
    "    Et2_right = get_value(row[\"right_ips\"], Et_2[\"start\"], Et_2[\"end\"], Et_2[\"right\"])\r\n",
    "\r\n",
    "    ethanol_list.append([Et1_left, Et1_right, Et2_left, Et2_right])\r\n",
    "    \r\n",
    "ethanol_peak_df = pd.DataFrame(ethanol_list, columns = [\"Et1_left\", \"Et1_right\", \"Et2_left\", \"Et2_right\"], index = peak_df.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#calculate for each spectrum and each peak the peak_area.\r\n",
    "\r\n",
    "Et1 = [integrate_peaks(col_sum_df_filtered.iloc[i], ethanol_peak_df[\"Et1_left\"].iloc[i], ethanol_peak_df[\"Et1_right\"].iloc[i]) for i in range(len(col_sum_df_filtered))] #area for peak 1\r\n",
    "Et2 = [integrate_peaks(col_sum_df_filtered.iloc[i], ethanol_peak_df[\"Et2_left\"].iloc[i], ethanol_peak_df[\"Et2_right\"].iloc[i]) for i in range(len(col_sum_df_filtered))] #area for peak 2\r\n",
    "Et1_to_Et2 = [integrate_peaks((col_sum_df_filtered.iloc[i]), ethanol_peak_df[\"Et1_left\"].iloc[i], ethanol_peak_df[\"Et2_right\"].iloc[i]) for i in range(len(col_sum_df_filtered))] #area from start peak1 until end peak 2\r\n",
    "x = np.array([Et1, Et2, Et1_to_Et2]).T\r\n",
    "ethanol_area_df = pd.DataFrame(x, columns = [\"Et1_area\", \"Et2_area\", \"Et1_to_Et2\"], index = col_sum_df_filtered.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create dictionaries with key: ferm Nr. , value: DataFrame\r\n",
    "col_sum_dict_filtered = {}\r\n",
    "peak_dict = {}\r\n",
    "ethanol_area_dict = {}\r\n",
    "for ferm, df in offline_dict.items():\r\n",
    "    y = []\r\n",
    "    for frame in [col_sum_df_filtered, peak_df, ethanol_area_df]:\r\n",
    "        x = [frame.index.get_loc(r, 'nearest') for r in df.index.values]\r\n",
    "        x = frame.iloc[x]\r\n",
    "        y.append(x)\r\n",
    "    col_sum_dict_filtered[ferm], peak_dict[ferm], ethanol_area_dict[ferm] = y[0], y[1], y[2]\r\n",
    "\r\n",
    "for [ferm, df1], df2 in zip(ethanol_area_dict.items(), offline_dict.values()):\r\n",
    "    df1[\"cE\"] = df2[\"cE\"].values\r\n",
    "    df1[\"Fermentation\"] = fermentation[ferm]\r\n",
    "    ethanol_area_dict[ferm] = df1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#just plotting a few to show the considered cutout\r\n",
    "few = [2,6]\r\n",
    "for ferm, df in col_sum_dict_filtered.items():           \r\n",
    "    for i in few:\r\n",
    "        fig = px.line(y = df.iloc[i].values, x= df.columns.values,  title=str(df.index[i]))  #range_y=[0, zmax],\r\n",
    "        fig.update_xaxes(title_text='Normalized drift time')\r\n",
    "        fig.update_yaxes(title_text='Signal intensity [a.u.]')\r\n",
    "        fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot data together with peak info\r\n",
    "for [ferm, df1], df2 in zip(col_sum_dict_filtered.items(), peak_dict.values()):                 \r\n",
    "    few = np.arange(0, len(df1), 50)        # just a few, change last argument in arange to 1 for all\r\n",
    "    for i in few:\r\n",
    "        fig = make_subplots()\r\n",
    "        fig.add_trace(go.Scatter(x= df1.columns.values, y= df1.iloc[i, :], name= \"Signal\", mode = line))\r\n",
    "        fig.add_trace(go.Scatter(x= df2[\"position\"].iloc[i], y= df2[\"height\"].iloc[i], name= \"Peak position\", mode = \"markers\", marker = dict(color =  \"red\", size = 4)))\r\n",
    "        fig.add_trace(go.Scatter(x= df2[\"left_ips\"].iloc[i], y= df2[\"h_eval\"].iloc[i], name= \"left_w\", mode = \"markers\", marker = dict(color =  \"green\", size = 5, symbol = \"x\")))  #, symbol = 141\r\n",
    "        fig.add_trace(go.Scatter(x= df2[\"right_ips\"].iloc[i], y= df2[\"h_eval\"].iloc[i], name= \"right_W\", mode = \"markers\", marker = dict(color =  \"green\", size = 5, symbol = \"x\")))\r\n",
    "        \r\n",
    "        fig.layout[\"yaxis\"].title.text = \"Signal intensity [a.u.]\"\r\n",
    "        fig.layout[\"xaxis\"].title.text = \"Normalized drift time\"\r\n",
    "        \r\n",
    "        fig.update_layout(title_text = str(df1.index[i]))\r\n",
    "        fig.update_layout(showlegend=False) #no legend\r\n",
    "        fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plotting ethanol conc (HPLC) vs peak area for all experiments\r\n",
    "area_vs_conc_df = pd.concat([val for val in ethanol_area_dict.values()])\r\n",
    "area_vs_conc_df = area_vs_conc_df[area_vs_conc_df[\"cE\"] > 0] #everything above 0 for HPLC ethanol\r\n",
    "\r\n",
    "#plot for Et 2 peak\r\n",
    "fig = px.scatter(area_vs_conc_df, x= \"Et2_area\" , y= \"cE\", color= \"Fermentation\", hover_name= area_vs_conc_df.index, labels={'cE': 'Ethanol HPLC [g/L]', 'Et2_area': 'Area ethanol peak 2 [a.u.]', 'Fermentation' : 'Experiment'}) \r\n",
    "\r\n",
    "#comment in or out plot for Et1_to_Et2\r\n",
    "#for plotting area integrated from left border et1 to right border et2 ... similiar results like PCA\r\n",
    "#fig = px.scatter(area_vs_conc_df, x= \"Et1_to_Et2\" , y= \"cE\", color= \"Fermentation\", hover_name= area_vs_conc_df.index, labels={ 'cE' : 'Ethanol HPLC [g/L]', 'Et1_to_Et2': 'Area from ethanol peak 1 to ethanol peak 2 [a.u.]' , 'Fermentation' : 'Experiment'}) \r\n",
    "\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#statistics to demonstrate how PC1 correlate with measured HPLC ethanol concentration\r\n",
    "# Pearson coefficient  \r\n",
    "pearson_coeff1 = area_vs_conc_df[\"Et2_area\"].corr(area_vs_conc_df[\"cE\"], method = \"pearson\")\r\n",
    "pearson_coeff2 = area_vs_conc_df[\"Et1_to_Et2\"].corr(area_vs_conc_df[\"cE\"], method = \"pearson\")\r\n",
    "\r\n",
    "#Spearman coefficient  \r\n",
    "spearman_coeff1 = area_vs_conc_df[\"Et2_area\"].corr(area_vs_conc_df[\"cE\"], method = \"spearman\")\r\n",
    "spearman_coeff2 = area_vs_conc_df[\"Et1_to_Et2\"].corr(area_vs_conc_df[\"cE\"], method = \"spearman\")\r\n",
    "\r\n",
    "print(\"p1 :\" ,pearson_coeff1,\"p2 :\",pearson_coeff2,\"s1 :\", spearman_coeff1, \"s2 :\" , spearman_coeff2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plotting ethanol (HPLC) vs peak area (peak:et1,et2, et1 to et2 ) for each experiment \r\n",
    "for ferm, df in ethanol_area_dict.items():\r\n",
    "    df = df[df[\"cE\"] > 0.0] #everything above cE == 0.0\r\n",
    "    fig = make_subplots(cols = 3)\r\n",
    "    fig.add_trace(go.Scatter(y= df[\"cE\"], x= df[\"Et1_area\"], name= \"HPLC vs. Et1_area\" ,  mode = \"markers\", marker = dict(color =  \"green\", size = 3), text = df.index), row= 1 , col = 1)\r\n",
    "    fig.add_trace(go.Scatter(y= df[\"cE\"], x= df[\"Et2_area\"], name= \"HPLC vs. Et2_area\", mode = \"markers\", marker = dict(color =  \"red\", size = 3),text = df.index), row= 1 , col = 2)\r\n",
    "    fig.add_trace(go.Scatter(y= df[\"cE\"], x= df[\"Et1_to_Et2\"], name= \"HPLC vs. Et1_to_Et2_area\", mode = \"markers\", marker = dict(color =  \"blue\", size = 3),text = df.index), row= 1 , col = 3) \r\n",
    "    fig.update_yaxes(title_text=\"Ethanol HPLC [g/L]\")\r\n",
    "    fig.update_xaxes(title_text=\"Area ethanol peak 1 [a.u.]\", row=1, col=1)\r\n",
    "    fig.update_xaxes(title_text=\"Area ethanol peak 2 [a.u.]\",  row=1, col=2)\r\n",
    "    fig.update_xaxes(title_text=\"Area from ethanol peak 1 to ethanol peak 2 [a.u.]\",  row=1, col=3) #\r\n",
    "    fig.update_layout(title_text = fermentation[ferm])\r\n",
    "    fig.update_layout(width=1200)\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#perform linear regression model for predicting ethanol concentrations with ET1_to_Et2 vs HPLC measured ethanol\r\n",
    "from sklearn.linear_model import LinearRegression #\r\n",
    "from copy import deepcopy\r\n",
    "\r\n",
    "\r\n",
    "#excluding fermentation 3 from area_vs_conc_df\r\n",
    "no_ferm3 = area_vs_conc_df[(area_vs_conc_df.index >= pd.to_datetime(\"2020-12-03 08:00\"))] #\r\n",
    "\r\n",
    "#decide by commenting out either with fermentation 3 or without\r\n",
    "# X = area_vs_conc_df.loc[: ,[\"Et1_to_Et2\"]].values.reshape(-1,1) # with ferm 3\r\n",
    "# Y = area_vs_conc_df.loc[: ,[\"cE\"]].values.reshape(-1,1) #\r\n",
    "\r\n",
    "\r\n",
    "#decide by commenting out either with fermentation 3 or without, have to match with X\r\n",
    "X = no_ferm3.loc[: ,[\"Et1_to_Et2\"]].values.reshape(-1,1) # without ferm 3\r\n",
    "Y = no_ferm3.loc[: ,[\"cE\"]].values.reshape(-1,1) #\r\n",
    "\r\n",
    "\r\n",
    "#train\r\n",
    "lr = LinearRegression()\r\n",
    "lr.fit(X,Y)\r\n",
    "\r\n",
    "#predict\r\n",
    "X = ethanol_area_df.loc[: ,[\"Et1_to_Et2\"]].values.reshape(-1,1)\r\n",
    "Y_pred = lr.predict(X)\r\n",
    "prediction_df = deepcopy(ethanol_area_df)\r\n",
    "prediction_df[\"ethanol_predicted\"] = Y_pred\r\n",
    "\r\n",
    "\r\n",
    "filter1 = (prediction_df.index >= pd.to_datetime(\"2020-11-18 13:37\")) & (prediction_df.index <= pd.to_datetime(\"2020-11-19 13:00\"))\r\n",
    "filter2 = (prediction_df.index >= pd.to_datetime(\"2020-12-03 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-04 13:00\"))\r\n",
    "filter3 = (prediction_df.index >= pd.to_datetime(\"2020-12-09 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-10 13:00\"))\r\n",
    "\r\n",
    "IMS_peak_extraction_dict = {\"ferm3\" : prediction_df[filter1], \"ferm6\" : prediction_df[filter2], \"ferm7\" : prediction_df[filter3]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot linear regression prediction results\r\n",
    "for [ferm, df1], df2 in zip(IMS_peak_extraction_dict.items(), offline_dict.values()):\r\n",
    "    df1 = df1[df1[\"ethanol_predicted\"] >= -1]\r\n",
    "    fig = make_subplots()\r\n",
    "    fig.add_trace(go.Scatter(x= df1.index, y= df1[\"ethanol_predicted\"], name = \"Ethanol estimated\", mode = \"lines+markers\"))\r\n",
    "    fig.add_trace(go.Scatter(x= df2.index, y= df2[\"cE\"], name = \"Ethanol HPLC\", mode = \"lines+markers\"))\r\n",
    "    fig.update_xaxes(title_text=\"Day/Time\")\r\n",
    "    fig.update_yaxes(title_text=\"Ethanol [g/L]\")\r\n",
    "    fig.update_layout(title_text = fermentation[ferm])\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Same for Et_2 area\r\n",
    "from sklearn.linear_model import LinearRegression #\r\n",
    "from copy import deepcopy\r\n",
    "\r\n",
    "\r\n",
    "#excluding fermentation 3 from area_vs_conc_df\r\n",
    "no_ferm3 = area_vs_conc_df[(area_vs_conc_df.index >= pd.to_datetime(\"2020-12-03 08:00\"))] #\r\n",
    "\r\n",
    "#decide by commenting out either with fermentation 3 or without\r\n",
    "#X = area_vs_conc_df.loc[: ,[\"Et2_area\"]].values.reshape(-1,1) # with ferm 3\r\n",
    "X = no_ferm3.loc[: ,[\"Et2_area\"]].values.reshape(-1,1) # without ferm 3\r\n",
    "\r\n",
    "#decide by commenting out either with fermentation 3 or without, have to match with X\r\n",
    "#Y = area_vs_conc_df.loc[: ,[\"cE\"]].values.reshape(-1,1) #\r\n",
    "Y = no_ferm3.loc[: ,[\"cE\"]].values.reshape(-1,1) #\r\n",
    "\r\n",
    "#train\r\n",
    "lr = LinearRegression()\r\n",
    "lr.fit(X,Y)\r\n",
    "\r\n",
    "#predict\r\n",
    "X = ethanol_area_df.loc[: ,[\"Et2_area\"]].values.reshape(-1,1)\r\n",
    "Y_pred = lr.predict(X)\r\n",
    "prediction_df = deepcopy(ethanol_area_df)\r\n",
    "prediction_df[\"ethanol_predicted\"] = Y_pred\r\n",
    "\r\n",
    "filter1 = (prediction_df.index >= pd.to_datetime(\"2020-11-18 13:37\")) & (prediction_df.index <= pd.to_datetime(\"2020-11-19 13:00\"))\r\n",
    "filter2 = (prediction_df.index >= pd.to_datetime(\"2020-12-03 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-04 13:00\"))\r\n",
    "filter3 = (prediction_df.index >= pd.to_datetime(\"2020-12-09 08:00\")) & (prediction_df.index <= pd.to_datetime(\"2020-12-10 13:00\"))\r\n",
    "\r\n",
    "IMS_peak_extraction_dict = {\"ferm3\" : prediction_df[filter1], \"ferm6\" : prediction_df[filter2], \"ferm7\" : prediction_df[filter3]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot linear regression prediction results\r\n",
    "for [ferm, df1], df2 in zip(IMS_peak_extraction_dict.items(), offline_dict.values()):\r\n",
    "    df1 = df1[df1[\"ethanol_predicted\"] >= -1]\r\n",
    "    fig = make_subplots()\r\n",
    "    fig.add_trace(go.Scatter(x= df1.index, y= df1[\"ethanol_predicted\"], name = \"Ethanol estimated\"))\r\n",
    "    fig.add_trace(go.Scatter(x= df2.index, y= df2[\"cE\"], name = \"Ethanol HPLC\"))\r\n",
    "    fig.update_xaxes(title_text=\"Day/Time\")\r\n",
    "    fig.update_yaxes(title_text=\"Ethanol [g/L]\")\r\n",
    "    fig.update_layout(title_text = fermentation[ferm])\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}